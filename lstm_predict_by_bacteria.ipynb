{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMtnnsCxxN40tQNmfqWELRi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ofakduman/Lstm-forecasting/blob/main/lstm_predict_by_bacteria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Zr8iSkgcrVnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/LSTM_forecasting/final_data.csv\")"
      ],
      "metadata": {
        "id": "qq4WGp_6rZrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "NDIRGqAFrpX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "organism_columns = ['Organism_Bacillus cereus', 'Organism_Listeria monocytogenes/innocua', 'Organism_Pseudomonads', 'Organism_Salmonella spp']\n",
        "\n",
        "organism_counts = df[organism_columns].sum()\n",
        "\n",
        "# Histogramı çiz\n",
        "organism_counts.plot(kind='bar')\n",
        "plt.title('Organism Türlerinin Dağılımı')\n",
        "plt.xlabel('Organism Türü')\n",
        "plt.ylabel('Frekans')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PInyk8xEr5HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Organism_Bacillus cereus' sütunu 1 olan satırları seç\n",
        "bacillus_cereus_df = df[df['Organism_Bacillus cereus'] == 1]\n",
        "\n",
        "# Sonuçları göster\n",
        "bacillus_cereus_df.head(10)\n"
      ],
      "metadata": {
        "id": "0-RNYjgOs-X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# df DataFrame'ini ilk olarak eğitim ve test setlerine ayır\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# df_train DataFrame'ini daha sonra eğitim ve doğrulama setlerine ayır\n",
        "df_train_partial, df_val = train_test_split(df_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Q6oNGeJEtiq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def prepare_data(df):\n",
        "    X, y = [], []\n",
        "    exclude_columns = ['Record ID', 'Total Values', 'Increases', 'Decreases', 'Logcs'] + organism_columns\n",
        "\n",
        "    # all_features listesini oluşturma\n",
        "    all_features = [col for col in df.columns if col not in exclude_columns]\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        logcs_data = row['Logcs']\n",
        "\n",
        "        # logcs_data'nın formatını kontrol et\n",
        "        if isinstance(logcs_data, str):\n",
        "            # Eğer string ise, uygun formata dönüştür\n",
        "            logcs_data = eval(logcs_data)\n",
        "\n",
        "        # all_features kullanarak özellikleri seç\n",
        "        features = row[all_features].values\n",
        "\n",
        "        if len(logcs_data) > 5:\n",
        "            X_input = []\n",
        "            for i in range(5):\n",
        "                # Hem zamanı hem de değeri ekle\n",
        "                X_input.extend([logcs_data[i][0], logcs_data[i][1]])\n",
        "                X_input.extend(features)\n",
        "\n",
        "            y_output = [logcs_data[i][1] for i in range(5, len(logcs_data))]\n",
        "\n",
        "            X.append(X_input)\n",
        "            y.append(y_output)\n",
        "\n",
        "    feature_len = 2 + len(all_features)  # Her zaman adımı için zaman ve değer\n",
        "    time_steps = 5\n",
        "    return np.array(X).reshape(-1, time_steps, feature_len), np.array(y, dtype=object)\n",
        "\n",
        "\n",
        "# Modelin geri kalan kısmı aynı kalabilir\n",
        "X_train, y_train = prepare_data(df_train_partial)\n",
        "X_val, y_val = prepare_data(df_val)\n",
        "X_test, y_test = prepare_data(df_test)\n"
      ],
      "metadata": {
        "id": "NHe0076Ft66u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
        "import numpy as np\n",
        "\n",
        "# Maksimum çıktı uzunluğunu hesapla\n",
        "max_output_length = max([len(yi) for yi in y_train])\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(5, len(X_train[0][0])))  # 5 zaman adımı, özellik sayısı\n",
        "encoder_lstm = LSTM(100, return_state=True, return_sequences=True)  # Nöron sayısını artırdık\n",
        "encoder_lstm_2 = LSTM(100, return_state=True)  # İkinci bir LSTM katmanı ekledik\n",
        "encoder_outputs, state_h, state_c = encoder_lstm_2(encoder_lstm(encoder_inputs))\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = RepeatVector(max_output_length)(encoder_outputs)\n",
        "decoder_lstm = LSTM(100, return_sequences=True, return_state=True)  # Nöron sayısını artırdık\n",
        "decoder_lstm_2 = LSTM(100, return_sequences=True, return_state=False)  # İkinci bir LSTM katmanı ekledik\n",
        "decoder_outputs = decoder_lstm_2(decoder_lstm(decoder_inputs, initial_state=encoder_states))\n",
        "decoder_dense = TimeDistributed(Dense(1))  # Her zaman adımı için bir tahmin\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=encoder_inputs, outputs=decoder_outputs)\n",
        "\n",
        "# Model Derleme\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Model Özeti\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qqPgTWxDuCKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "epochs = 20  # Toplam epoch sayısı\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    total_train_loss = 0\n",
        "    total_val_loss = 0\n",
        "\n",
        "    # Eğitim döngüsü\n",
        "    for i in range(len(X_train)):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_train[i:i+1], training=True)\n",
        "            train_loss = loss_fn(y_train[i], y_pred[0, :len(y_train[i]), 0])\n",
        "        gradients = tape.gradient(train_loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        total_train_loss += train_loss.numpy()\n",
        "\n",
        "    # Doğrulama döngüsü\n",
        "    for i in range(len(X_val)):\n",
        "        # X_val[i:i+1] dizisini tensöre dönüştür\n",
        "        X_val_tensor = tf.convert_to_tensor(X_val[i:i+1], dtype=tf.float32)\n",
        "        y_pred_val = model.predict(X_val_tensor)\n",
        "\n",
        "        # y_val[i] dizisini tensöre dönüştür\n",
        "        y_val_tensor = tf.convert_to_tensor(y_val[i], dtype=tf.float32)\n",
        "\n",
        "        # Tahmin ve gerçek değerlerin boyutlarını eşitle\n",
        "        min_length = min(y_pred_val.shape[1], len(y_val[i]))\n",
        "        val_loss = loss_fn(y_val_tensor[:min_length], y_pred_val[0, :min_length, 0])\n",
        "\n",
        "        total_val_loss += val_loss.numpy()\n",
        "\n",
        "    # Ortalama kayıpları hesapla ve kaydet\n",
        "    avg_train_loss = total_train_loss / len(X_train)\n",
        "    avg_val_loss = total_val_loss / len(X_val)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    print(f\"Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}\")\n",
        "\n",
        "# Kayıpları grafik üzerinde görselleştirme\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Train & Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k2-fsUfswduj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "xr3ORj8CwhCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mse_values = []\n",
        "    mae_values = []\n",
        "    r2_values = []\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        true_values = np.array(y_true[i])\n",
        "        pred_values = y_pred[i, :len(y_true[i]), 0]\n",
        "\n",
        "        mse = mean_squared_error(true_values, pred_values)\n",
        "        mae = mean_absolute_error(true_values, pred_values)\n",
        "\n",
        "        mse_values.append(mse)\n",
        "        mae_values.append(mae)\n",
        "\n",
        "        # R2 skorunu yalnızca birden fazla değeri olan örnekler için hesap\n",
        "        if len(true_values) > 1:\n",
        "            r2 = r2_score(true_values, pred_values)\n",
        "            r2_values.append(r2)\n",
        "\n",
        "    return np.mean(mse_values), np.mean(mae_values), np.mean(r2_values) if r2_values else np.nan\n",
        "\n",
        "# Hata metriklerini hesaplama\n",
        "mse, mae, r2 = calculate_metrics(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"R2 Score:\", r2)\n"
      ],
      "metadata": {
        "id": "WKzP5duiHF88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "selected_indices = random.sample(range(len(y_test)), 55)\n",
        "\n",
        "for index in selected_indices:\n",
        "    plt.figure(figsize=(8, 4))  # Grafik boyutu\n",
        "    plt.plot(y_test[index], marker='o', label='y_test')\n",
        "\n",
        "    # y_pred verisini y_test verisinin uzunluğu\n",
        "    y_pred_trimmed = y_pred[index][:len(y_test[index])]\n",
        "    plt.plot(y_pred_trimmed, marker='x', label='y_pred')\n",
        "\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.title(f'Sample {index + 1}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RQL50yatHINa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pf61VtDMHPbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}